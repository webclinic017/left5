{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "weird-metro",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import copy\n",
    "import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "\n",
    "# from sklearn import tree, svm\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams['lines.linewidth'] = .5\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['figure.figsize'] = (16, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22349b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lutils.fin.autoencoder import Autoencoder, Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "913e4c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.set_printoptions(precision=4, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "saved-september",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2a44eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lutils.fin.data_loader import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f1c6d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rbs = (\n",
    "#     ('2021-04-06', 'SHFE.rb2110'),\n",
    "#     ('2021-08-10', 'SHFE.rb2201'),\n",
    "#     ('2021-11-25', 'SHFE.rb2205'),\n",
    "#     ('2022-03-29', 'SHFE.rb2210'),\n",
    "#     ('2022-08-30', 'SHFE.rb2301'),\n",
    "#     ('2022-12-02', 'SHFE.rb2305'),\n",
    "#     ('2023-04-04', 'SHFE.rb2310'),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5226039f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs = []\n",
    "# for i, (d, exchange_symbol) in enumerate(rbs):\n",
    "#     start_date = d\n",
    "    \n",
    "#     exchange, symbol = exchange_symbol.split('.')\n",
    "#     df = load(exchange, symbol)\n",
    "#     df.index = df.datetime\n",
    "#     if i < len(rbs) - 1:\n",
    "#         end_date = rbs[i+1][0]\n",
    "#         dfs.append(df[(df.index >= start_date) & (df.index < end_date)])\n",
    "#     else:\n",
    "#         dfs.append(df[start_date:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36dc9245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f47e55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store = pd.HDFStore('D:/option/rb.h5', 'w', complevel=7)\n",
    "# store.append('rb', df)\n",
    "# store.flush()\n",
    "# store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f634897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store = pd.HDFStore('D:/option/rb.h5', 'r')\n",
    "# df = store['rb']\n",
    "# store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e7bd229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(df.loc['2021-05-10'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8aef665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b30a2e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_df(df, exchange, symbol, rule):\n",
    "    \n",
    "    between_times = [['09:00', '10:15'], ['10:30', '11:30'], ['13:30', '15:00'], ['21:00', '23:00']]\n",
    "    \n",
    "    dfs = []\n",
    "    with tqdm.tqdm(np.unique(df.index.date)) as bar:\n",
    "        bar.set_description('%s %s' % (exchange, symbol))\n",
    "        for d in bar:\n",
    "            bar.set_postfix({'date': d})\n",
    "            df_day = df[df.index.date == d]\n",
    "            \n",
    "            if df_day.shape[0] > 0:\n",
    "                df_resample_sec = df_day.resample(rule).last()\n",
    "            \n",
    "                for (start, end) in between_times:\n",
    "                    df_hour = df_resample_sec.between_time(start, end)\n",
    "\n",
    "                    if df_hour.shape[0] > 0:\n",
    "                        dfs.append(df_hour)\n",
    "                    \n",
    "            \n",
    "    if len(dfs) > 0:\n",
    "        df_sec = pd.concat(dfs)\n",
    "    \n",
    "        store = pd.HDFStore(os.path.join('D:/option', '%s.%s_%s.h5' % (exchange, symbol, rule)), 'w', complevel=7)\n",
    "        store.append(symbol, df_sec)\n",
    "        store.flush()\n",
    "        store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "587cd710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample_df(df, 'SHFE', 'rb', '1S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad01a7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = pd.HDFStore('D:/option/SHFE.rb_1S.h5', 'r')\n",
    "df = store['rb']\n",
    "store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e61721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9a81b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RbDataset(Dataset):\n",
    "    def __init__(self, x):\n",
    "#         x = np.log(x)\n",
    "#         x = np.diff(x, n=1)\n",
    "        x = x.reshape([-1, 1])\n",
    "        self.x = x.astype(np.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "462eddb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 0\n",
    "n_epochs = 40\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b88c8905",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_index = int(df.shape[0] * .8)\n",
    "        \n",
    "data_train = df[:split_index]\n",
    "data_val = df[split_index:]\n",
    "\n",
    "dataset_train = RbDataset(data_train['last_price'].dropna().values)\n",
    "dataset_val = RbDataset(data_val['last_price'].dropna().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d96cec3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(dataset_val, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e958305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Autoencoder(nn.Module):\n",
    "#     def __init__(self): # 1 1\n",
    "#         super(Autoencoder, self).__init__()\n",
    "        \n",
    "#         self.encoder = nn.Sequential(\n",
    "#             nn.Linear(1, 256),\n",
    "#             nn.BatchNorm1d(256),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(256, 128),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(128, 64),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(64, 32),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(32, 1),\n",
    "#         )\n",
    "        \n",
    "#         self.decoder = nn.Sequential(\n",
    "#             nn.Linear(1, 32),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(32, 64),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(64, 128),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(128, 256),\n",
    "#             nn.ReLU(),\n",
    "#             nn.BatchNorm1d(256),\n",
    "#             nn.Linear(256, 1),\n",
    "#         )\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         encoded = self.encoder(x)\n",
    "#         return self.decoder(encoded), encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ae824e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Autoencoder(nn.Module):\n",
    "#     def __init__(self): # 1 1\n",
    "#         super(Autoencoder, self).__init__()\n",
    "        \n",
    "#         self.encoder = nn.Sequential(\n",
    "#             nn.Linear(1, 128),\n",
    "#             nn.BatchNorm1d(128),\n",
    "#             nn.Sigmoid(),\n",
    "#             nn.Linear(128, 64),\n",
    "#             nn.Sigmoid(),\n",
    "#             nn.Linear(64, 32),\n",
    "#             nn.Sigmoid(),\n",
    "#             nn.Linear(32, 1),\n",
    "#         )\n",
    "        \n",
    "#         self.decoder = nn.Sequential(\n",
    "#             nn.Linear(1, 32),\n",
    "#             nn.Sigmoid(),\n",
    "#             nn.Linear(32, 64),\n",
    "#             nn.Sigmoid(),\n",
    "#             nn.Linear(64, 128),\n",
    "#             nn.Sigmoid(),\n",
    "#             nn.BatchNorm1d(128),\n",
    "#             nn.Linear(128, 1),\n",
    "#         )\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         encoded = self.encoder(x)\n",
    "#         return self.decoder(encoded), encoded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4307926c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Autoencoder(nn.Module):\n",
    "#     def __init__(self): # 1 1\n",
    "#         super(Autoencoder, self).__init__()\n",
    "        \n",
    "#         self.encoder = nn.Sequential(\n",
    "#             nn.Linear(1, 128),\n",
    "#             nn.BatchNorm1d(128),\n",
    "#             nn.Sigmoid(),\n",
    "#             nn.Linear(128, 64),\n",
    "#             nn.BatchNorm1d(64),\n",
    "#             nn.Sigmoid(),\n",
    "#             nn.Linear(64, 32),\n",
    "#             nn.BatchNorm1d(32),\n",
    "#             nn.Sigmoid(),\n",
    "#             nn.Linear(32, 1),\n",
    "#         )\n",
    "        \n",
    "#         self.decoder = nn.Sequential(\n",
    "#             nn.Linear(1, 32),\n",
    "#             nn.BatchNorm1d(32),\n",
    "#             nn.Sigmoid(),\n",
    "#             nn.Linear(32, 64),\n",
    "#             nn.BatchNorm1d(64),\n",
    "#             nn.Sigmoid(),\n",
    "#             nn.Linear(64, 128),\n",
    "#             nn.BatchNorm1d(128),\n",
    "#             nn.Sigmoid(),\n",
    "#             nn.Linear(128, 1),\n",
    "#         )\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         encoded = self.encoder(x)\n",
    "#         return self.decoder(encoded), encoded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4b63b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Autoencoder(nn.Module):\n",
    "#     def __init__(self): # 1 1\n",
    "#         super(Autoencoder, self).__init__()\n",
    "        \n",
    "#         self.encoder = nn.Sequential(\n",
    "#             nn.Linear(1, 256),\n",
    "#             nn.BatchNorm1d(256),\n",
    "#             nn.Sigmoid(),\n",
    "#             nn.Linear(256, 128),\n",
    "#             nn.Sigmoid(),\n",
    "#             nn.Linear(128, 64),\n",
    "#             nn.Sigmoid(),\n",
    "#             nn.Linear(64, 32),\n",
    "#             nn.Sigmoid(),\n",
    "#             nn.Linear(32, 1),\n",
    "            \n",
    "#             nn.BatchNorm1d(1),\n",
    "#         )\n",
    "        \n",
    "#         self.decoder = nn.Sequential(\n",
    "#             nn.Linear(1, 32),\n",
    "#             nn.Sigmoid(),\n",
    "#             nn.Linear(32, 64),\n",
    "#             nn.Sigmoid(),\n",
    "#             nn.Linear(64, 128),\n",
    "#             nn.Sigmoid(),\n",
    "#             nn.Linear(128, 256),\n",
    "#             nn.Sigmoid(),\n",
    "#             nn.BatchNorm1d(256),\n",
    "#             nn.Linear(256, 1),\n",
    "#         )\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         encoded = self.encoder(x)\n",
    "#         return self.decoder(encoded), encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "808256d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Autoencoder(nn.Module):\n",
    "#     def __init__(self): # 1 1\n",
    "#         super(Autoencoder, self).__init__()\n",
    "        \n",
    "#         self.encoder = nn.Sequential(\n",
    "#             nn.Linear(1, 256, bias=False), # 32 256\n",
    "#             nn.LayerNorm(256, elementwise_affine=False),\n",
    "#             nn.Sigmoid(),\n",
    "#             nn.Linear(256, 128),\n",
    "#             nn.Sigmoid(),\n",
    "#             nn.Linear(128, 64),\n",
    "#             nn.Sigmoid(),\n",
    "#             nn.Linear(64, 32),\n",
    "#             nn.Sigmoid(),\n",
    "#             nn.Linear(32, 1),\n",
    "            \n",
    "#             nn.LayerNorm(1, elementwise_affine=False),\n",
    "#         )\n",
    "        \n",
    "#         self.decoder = nn.Sequential(\n",
    "#             nn.Linear(1, 32),\n",
    "#             nn.Sigmoid(),\n",
    "#             nn.Linear(32, 64),\n",
    "#             nn.Sigmoid(),\n",
    "#             nn.Linear(64, 128),\n",
    "#             nn.Sigmoid(),\n",
    "#             nn.Linear(128, 256),\n",
    "#             nn.Sigmoid(),\n",
    "#             nn.LayerNorm(256, elementwise_affine=False),\n",
    "#             nn.Linear(256, 1),\n",
    "#         )\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         encoded = self.encoder(x)\n",
    "#         return self.decoder(encoded), encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea984827",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self): # 1 1\n",
    "        super(Autoencoder, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(1, 256), # 32 256\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(32, 16),\n",
    "            \n",
    "            nn.Softmax(1)\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(16, 32),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.Sigmoid(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, 1),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        return self.decoder(encoded), encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "86be5048",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d6a2c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.98), eps=1e-9)\n",
    "lambda1 = lambda epoch: np.power(0.1, epoch) if epoch <= 8 else 1e-9\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8596e8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "027587be",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18176\\776103873.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\Python\\torch\\lib\\site-packages\\torch\\optim\\lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     66\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[1;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\Python\\torch\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m                     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m                     \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\Python\\torch\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'differentiable'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprev_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\Python\\torch\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[0;32m    250\u001b[0m                  \u001b[0mfused\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'fused'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m                  \u001b[0mgrad_scale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgrad_scale\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m                  found_inf=found_inf)\n\u001b[0m\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\Python\\torch\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    314\u001b[0m          \u001b[0mdifferentiable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdifferentiable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m          \u001b[0mgrad_scale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgrad_scale\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m          found_inf=found_inf)\n\u001b[0m\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\Python\\torch\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m         \u001b[1;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mexp_avg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m         \u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "step = 0\n",
    "for epoch in range(n_epochs):\n",
    "    running_loss = 0\n",
    "    for idx, (X_batch) in enumerate(train_dataloader, 1):\n",
    "        X_batch = X_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred, encoded = model(X_batch)\n",
    "        loss = criterion(y_pred, X_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * X_batch.shape[0]\n",
    "\n",
    "        step += X_batch.shape[0]\n",
    "#         print(encoder_out)\n",
    "\n",
    "        if idx % 5000 == 0:\n",
    "            writer.add_scalar('loss/loss', loss.item(), step)\n",
    "            writer.add_scalar('loss/total_loss', running_loss / step, step)\n",
    "#             print(X_batch)\n",
    "#             print(encoder_out, y_pred)\n",
    "            writer.add_histogram('train/01_x', X_batch.data.cpu(), step)\n",
    "            writer.add_histogram('train/02_encoder', encoded.data.cpu(), step)\n",
    "            \n",
    "            writer.add_histogram('train/03_pred', y_pred.data.cpu(), step)\n",
    "#             writer.add_histogram('train/04_linear', out, step)\n",
    "    \n",
    "    lr = scheduler.get_last_lr()[0]\n",
    "    print('Epoch: [{}/{}], Loss: {:.8f}, lr:{:.16f}'.format(epoch + 1, n_epochs, running_loss / (step), lr))\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a622938e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'D:/option/models/SHFE.rb_encoder_256.pt')\n",
    "# torch.save(model.state_dict(), 'D:/option/models/SHFE.rb_encoder_128.pt')\n",
    "# torch.save(model.state_dict(), 'D:/option/models/SHFE.rb_encoder_128_n.pt')\n",
    "# torch.save(model.state_dict(), 'D:/option/models/SHFE.rb_encoder_tanh.pt')\n",
    "torch.save(model.state_dict(), 'D:/option/models/SHFE.rb_encoder_bn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d557c15f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.load_state_dict(torch.load('D:/option/models/SHFE.rb_encoder.pt'))\n",
    "# model.load_state_dict(torch.load('D:/option/models/SHFE.rb_encoder_256.pt'))\n",
    "# model.load_state_dict(torch.load('D:/option/models/SHFE.rb_encoder_128.pt'))\n",
    "# model.load_state_dict(torch.load('D:/option/models/SHFE.rb_encoder_128_n.pt'))\n",
    "# model.load_state_dict(torch.load('D:/option/models/SHFE.rb_encoder_bn.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6ce69a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2515989a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "94ca9ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for idx, (X_batch) in enumerate(val_dataloader, 1):\n",
    "    print(idx)\n",
    "    X_batch = X_batch.to(device)\n",
    "    y_pred, encoder_out = model(X_batch)\n",
    "#     print(X_batch)\n",
    "#     print(y_pred)\n",
    "\n",
    "#     plt.plot(np.exp(y_pred.cpu().detach().numpy()), label='pred')\n",
    "#     plt.plot(np.exp(X_batch.cpu().detach().numpy()), label='real')\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "#     plt.savefig(os.path.join('D:/option/xxx', '%s.jpg' % idx), dpi=160)\n",
    "#     plt.close()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1c60415a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1099],\n",
       "        [-1.0078],\n",
       "        [-1.2392],\n",
       "        [-2.1602],\n",
       "        [-0.4577],\n",
       "        [-0.6896],\n",
       "        [-0.7609],\n",
       "        [-1.8314],\n",
       "        [-1.8560],\n",
       "        [-0.8191],\n",
       "        [-0.5836],\n",
       "        [-0.7513],\n",
       "        [-0.4728],\n",
       "        [-0.3604],\n",
       "        [-1.1499],\n",
       "        [-1.8406],\n",
       "        [-0.7633],\n",
       "        [-2.6426],\n",
       "        [-0.5232],\n",
       "        [-0.8142],\n",
       "        [-1.1365],\n",
       "        [-0.5566],\n",
       "        [-0.3728],\n",
       "        [-0.8265],\n",
       "        [-0.7729],\n",
       "        [-2.0270],\n",
       "        [-0.8684],\n",
       "        [-2.4859],\n",
       "        [-0.9009],\n",
       "        [-0.1378],\n",
       "        [-0.5454],\n",
       "        [-0.8314]], device='cuda:0', grad_fn=<NativeBatchNormBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e9e20cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_pred.cpu().detach().numpy() - 50, label='pred')\n",
    "plt.plot(X_batch.cpu().detach().numpy(), label='real')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bc589a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
