{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metropolis-Hastings algorithm\n",
    "\n",
    "In this notebook, I will implement Metropolis-Hastings algorithm, a popular example of Markov Chain Monte Carlo sampling method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Theory\n",
    "\n",
    "## 1.1 Notation\n",
    "\n",
    "Let us define notations as follows: \n",
    "* $X$ : a set (or more precisely, a measurable space with an appropriate sigma algebra), on which we consider probability distribution \n",
    "* $p(x) = \\tilde{p}(x)/Z_p$ : the density function of the distribution from which we want to sample, where the constant $Z_p$ can be unknown.\n",
    "* $q(x|x')$ : proporsal kernel, where $q(x|x')$ stands for the probability density of getting $x$ as a candidate, provided that we have $x'$ now. \n",
    "\n",
    "## 1.2 Algorithm\n",
    "\n",
    "* input : the initial point $x^{ini} \\in X$, the number of samples required $N$\n",
    "* output : the sequence of variables $x^{(0)}, x^{(1)}, \\dots x^{(N-1)}$, which (approximately) obey the distribution $p$.\n",
    "* Given $x^{current}$, generate $x^{tmp}$ according to $q(\\cdot | x^{current})$. \n",
    "* Set the next state $x^{next}$ as \n",
    "$$\n",
    "\\begin{align}\n",
    "    x^{next} = \n",
    "    \\begin{cases}\n",
    "        x^{tmp} & (\\mbox{with probability } A(x^{tmp}, x^{current})) \\\\ \n",
    "        x^{current} & (\\mbox{with probability } 1 - A(x^{tmp}, x^{current}))\n",
    "    \\end{cases},\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    A(x,y) := \\min\\left( 1, \\ \\frac{\\tilde{p}(x)}{\\tilde{p}(y)}\\cdot \\frac{q(y|x)}{q(x|y)} \\right)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 From math to code\n",
    "\n",
    "We will define `MHsampler` class, which gives us samples according to the algorithm stated in the previous section.\n",
    "\n",
    "Hereafter,\n",
    "* we assume $X$ to be $D$ dimensional Euclidean space, and \n",
    "* use a $D$ dimensional gaussian distribution with a given covariance matrix $\\Sigma$ as the proporsal kernel : \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    q(x|y) = \\frac{1}{(2\\pi)^{D/2} \\sqrt{\\det \\Sigma}} \\exp\\left[ -\\frac{1}{2}(x-y)^T \\Sigma^{-1} (x-y) \\right]\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Note that because of the symmetry of the proposal kernel, the algorithm reduces to Metropolis algorithm, and hence we have\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    A(x,y) := \\min\\left( 1, \\ \\frac{\\tilde{p}(x)}{\\tilde{p}(y)} \\right)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "## 2.1 Properties and methods\n",
    "\n",
    "We let `MHsampler` class has the following properties and methods\n",
    "\n",
    "### 2.1.1 Properties\n",
    "\n",
    "* `D` : $D$. i.e., the dimension of the Euclidean space $X$.\n",
    "* `sigma` : $\\Sigma$, i.e., the covariance matrix of the proporsal kernel\n",
    "* `p` : $\\tilde{p}$, (possibly not normalized) probability density function of the target distribution\n",
    "\n",
    "\n",
    "### 2.1.2 Methods\n",
    "\n",
    "* `_A` : $A$, the acceptance probability.\n",
    "* `sample` : method that returns samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetropolisSampler:\n",
    "    def __init__(self, D, sigma, p):\n",
    "        self.D = D # the dimension of the output space       \n",
    "        self.sigma = sigma # the covariance matrix of the proporsal kernel\n",
    "        self.p = p # the density function of the target distribution\n",
    "    \n",
    "    def _A(self, x, y):\n",
    "        '''\n",
    "        The method which returns the acceptance probability, \n",
    "        depending on the current state y and the candidate state x\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 1D numpy array\n",
    "            1D numpy array representing the candidate state\n",
    "        y : 1D numpy array\n",
    "            1D numpy array representing the current state\n",
    "        Returns \n",
    "        ----------\n",
    "        A : float\n",
    "            The acceptance probability A(x, y), \n",
    "            where y is the current state, and x is the candidate state.\n",
    "        '''\n",
    "        denom = self.p(y)  # for avoiding zero division error\n",
    "        if denom == 0:\n",
    "            return 1.0\n",
    "        else:\n",
    "            return min( 1.0, self.p(x) / denom )\n",
    "    \n",
    "    def sample(self, xini, N, stride):\n",
    "        '''\n",
    "        The method that performs sampling using Metropolis algorithm, and returns the samples\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        xini : 1D numpy array\n",
    "            1D numpy array representing the initial point\n",
    "        N : int\n",
    "            An integer representing the number of samples required.\n",
    "        stride : int\n",
    "            An integer representing how frequent samples are recorded.\n",
    "            More specifically, we only record sample once in `stride` steps\n",
    "            \n",
    "        Returns \n",
    "        ----------\n",
    "        X : 2D array\n",
    "            (N, self.D) array representing the obtained samples, where X[n] is the n-th sample.\n",
    "        '''\n",
    "        X = np.zeros((N, self.D))  # array for recording the sample\n",
    "        x = xini\n",
    "        cnt = 0\n",
    "        for i in range((N-1) * stride + 1):\n",
    "            xtmp = np.random.multivariate_normal(x, self.sigma)  # sample from the proporsal kernel (gaussian )\n",
    "            tmprand = random.random()\n",
    "            if tmprand < self._A(xtmp, x):\n",
    "                x = xtmp\n",
    "            if i % stride == 0:\n",
    "                X[cnt] = x\n",
    "                cnt += 1\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Experiments\n",
    "\n",
    "We consider two exmples, namely, \n",
    "* gamma distribution (one dimensional)\n",
    "* two dimensional gaussian distribution\n",
    "\n",
    "For these distributions, and compare histograms generated from MCMC samples, and probability density functions.\n",
    "\n",
    "## 3.1 Gamma distribution (1-D)\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    & p(x) = \\frac{1}{\\Gamma(k) \\theta^k} x^{k-1} e^{-\\frac{x}{\\theta}} \\\\\n",
    "    & \\mbox{mean} : k \\theta \\\\\n",
    "    & \\mbox{variance} : k \\theta^2\n",
    "\\end{align}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgam(x):\n",
    "    if x > 0:\n",
    "        return (x**2)*np.exp(-x)\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "sampler = MetropolisSampler(D=1, sigma=np.array([[1.0]]), p=pgam)\n",
    "samples = sampler.sample(xini=np.array([1.0]), N=5000, stride=10)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"sample mean : {np.mean(samples)}\")\n",
    "print(f\"sample variance : {np.var(samples)}\")\n",
    "step = 0.25\n",
    "plt.hist(samples, bins=np.arange(0, 10, step), density=True, label=\"Normalized histogram\")\n",
    "xx = np.linspace(0,10,100)\n",
    "plt.plot(xx, 0.5*xx**2*np.exp(-xx), label=\"probability density function\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Two-dimensional normal distribution\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    & p(x) = \\frac{1}{2 \\pi \\sqrt{\\det \\Sigma}} \\exp\\left( -\\frac{1}{2} x^T \\Sigma^{-1} x \\right)  \\\\\n",
    "    & \\Sigma^{-1} = \\begin{pmatrix}\n",
    "    10 & -6  \\\\\n",
    "    -6 & 10\n",
    "    \\end{pmatrix} \\\\\n",
    "    & \\Sigma = \n",
    "    \\frac{1}{32}\n",
    "    \\begin{pmatrix}\n",
    "    5 & 3  \\\\\n",
    "    3 & 5\n",
    "    \\end{pmatrix}\n",
    "    = \\begin{pmatrix}\n",
    "    0.15625 & 0.09375  \\\\\n",
    "    0.09375 & 0.15625\n",
    "    \\end{pmatrix}\n",
    "\\end{align}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p(x):\n",
    "    precmat = np.array([[10,-6],[-6,10]])\n",
    "    return np.exp(-0.5*x @ precmat @ x)\n",
    "\n",
    "sampler = MetropolisSampler(D = 2, sigma = np.array([[1,0],[0,1]]), p = p)\n",
    "samples = sampler.sample(np.array([1,0]), N=5000, stride=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"sample mean : {np.mean(samples, axis=0)}\")\n",
    "print(f\"sample covariance : {np.cov(samples, rowvar=False)}\")\n",
    "\n",
    "# two dimensional histogram\n",
    "H, xx, yy = np.histogram2d(samples[:,0], samples[:,1], bins=25, normed=True)\n",
    "H = H.T\n",
    "XX, YY = np.meshgrid(xx, yy)\n",
    "\n",
    "# contour plot of the density function\n",
    "xx_f = np.linspace(-1.5,1.5,100)\n",
    "yy_f = np.linspace(-1.5,1.5,101)\n",
    "XX_f, YY_f = np.meshgrid(xx_f, yy_f)\n",
    "Z_f = np.exp( -0.5*( 10*XX_f*XX_f -12*XX_f*YY_f + 10*YY_f*YY_f ))/(2*np.pi)*8\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(121)\n",
    "plt.plot(samples[:,0], samples[:,1],',')\n",
    "plt.contour(XX_f,YY_f,Z_f)\n",
    "plt.colorbar()\n",
    "plt.subplot(122)\n",
    "plt.pcolormesh(XX, YY, H)\n",
    "plt.colorbar()\n",
    "plt.contour(XX_f,YY_f,Z_f)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
