{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "trying-surgery",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\code\\python\\pyfolio\\pyfolio\\pos.py:27: UserWarning: Module \"zipline.assets\" not found; multipliers will not be applied to position notionals.\n",
      "  'Module \"zipline.assets\" not found; multipliers will not be applied'\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import shapiro\n",
    "matplotlib.use('Agg')\n",
    "%matplotlib inline\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "from finrl.apps import config\n",
    "from finrl.finrl_meta.preprocessor.yahoodownloader import YahooDownloader\n",
    "from finrl.finrl_meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
    "from finrl.finrl_meta.env_portfolio_allocation.env_portfolio import StockPortfolioEnv\n",
    "from finrl.drl_agents.stablebaselines3.models import DRLAgent\n",
    "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline, get_baseline_tdx,convert_daily_return_to_pyfolio_ts\n",
    "\n",
    "import torch\n",
    "# import plotly.express as px\n",
    "\n",
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "from pypfopt import risk_models\n",
    "from pypfopt import EfficientFrontier\n",
    "from pypfopt import expected_returns\n",
    "from pypfopt import objective_functions\n",
    "from pyfolio import timeseries\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "british-video",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lutils.stock import LTdxHq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hourly-feelings",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start = '2019-01-01'\n",
    "train_end = '2022-02-13'\n",
    "trade_start = train_end\n",
    "trade_end = '2022-02-20'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "enclosed-seeking",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = pd.read_pickle('d:/ddf.pkl').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "wired-trick",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = ddf.sort_values(['date','tic'], ignore_index=True)\n",
    "ddf.index = ddf.date.factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "decreased-string",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1486,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "days = ddf.date.unique()\n",
    "days.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "developmental-bernard",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = ddf[(ddf['date'] > days[-63]) & (ddf['date'] < trade_start)]\n",
    "dd = dl.pivot_table(index = 'date',columns = 'tic', values = 'close').pct_change().dropna()\n",
    "corr = dd.cov().corr()\n",
    "# corr.style.background_gradient(cmap='coolwarm')\n",
    "\n",
    "# c1 = corr.abs().unstack().sort_values(ascending = True)\n",
    "# c1 = corr.unstack().sort_values(ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "preliminary-century",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "rotary-talent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr.unstack().sort_values().index.get_level_values(0)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "authorized-ethics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tic\n",
       "600890   -1039.481388\n",
       "002419   -1012.449304\n",
       "603102    -943.427207\n",
       "600652    -941.406310\n",
       "000573    -903.815285\n",
       "             ...     \n",
       "605151    1595.184572\n",
       "000759    1597.397651\n",
       "000019    1599.259939\n",
       "600879    1599.327920\n",
       "688505    1599.362602\n",
       "Length: 2395, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr.sum().sort_values() # ascending=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "victorian-vermont",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_codes = list(np.random.choice(ddf.tic.unique(), 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "structural-costa",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_codes = list(corr.unstack().sort_values().index.get_level_values(0)[:3])\n",
    "# ['601398', '000738']\n",
    "# ['601988', '603538'] # 2022-02-08\n",
    "# ['600377', '000887'] # 2022-02-14\n",
    "# ['301040', '000573'] # 2022-02-15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "timely-douglas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_codes = list(corr.sum().sort_values().index.values[:2]) # ascending=False\n",
    "# ['000921', '600365', '000609', '601868', '002372', '001965']\n",
    "# ['601868', '000501', '603789', '002311', '002873', '000921']\n",
    "# ['000921', '603789', '002372', '601868', '300675', '002032']\n",
    "# ['600775', '603789', '300622', '603228', '600172', '001965']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "express-importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_codes = ['601186', '002645', '600546', '688222', '600107', '603028']\n",
    "# stock_codes = ['601988', '603538']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "boolean-period",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['301040', '000573', '300384']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "surgical-shuttle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_codes = ['000921', '002032', '300406', '603789']\n",
    "# stock_codes = ['000609', '000921', '001965', '002372']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "capable-minority",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- over 301040 min: 2021-08-03 00:00:00 max: 2022-02-18 00:00:00 -----------\n",
      "----------- over 000573 min: 2018-01-02 00:00:00 max: 2022-02-18 00:00:00 -----------\n",
      "----------- over 300384 min: 2018-01-02 00:00:00 max: 2022-02-18 00:00:00 -----------\n"
     ]
    }
   ],
   "source": [
    "ltdxhq = LTdxHq()\n",
    "\n",
    "indexs = None\n",
    "dfs = []\n",
    "for code in stock_codes:\n",
    "    df = ltdxhq.get_k_data_daily(code, start='2018-01-01') # 2014-01-01\n",
    "    \n",
    "    if indexs is None:\n",
    "        indexs = df.index\n",
    "    else:\n",
    "        indexs = indexs.union(df.index)\n",
    "    \n",
    "#     df = df.assign(date = df.index)\n",
    "#     df = df.assign(day = df.index.weekday)\n",
    "#     df.date = df.date.dt.strftime('%Y-%m-%d')\n",
    "    df = df.assign(tic = code)\n",
    "#     df.index = range(df.shape[0])\n",
    "    \n",
    "    dfs.append(df)\n",
    "    print('----------- over %s min: %s max: %s -----------' % (code, df.index.min(), df.index.max()))\n",
    "\n",
    "for i, df in enumerate(dfs):\n",
    "    df = df.reindex(indexs)\n",
    "    df = df.assign(date = df.index)\n",
    "    df = df.assign(day = df.index.weekday)\n",
    "    df.index = range(df.shape[0])\n",
    "    \n",
    "    dfs[i] = df.ffill()\n",
    "    \n",
    "df = pd.concat(dfs)\n",
    "# df.index = range(df.shape[0])\n",
    "\n",
    "ltdxhq.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "promising-virtue",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "numerical-square",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist = df[df.tic == '601868 '].close.hist() # bins=3)\n",
    "\n",
    "# df[['open', 'close', 'high', 'low']].plot.hist(bins=100, alpha=0.5)\n",
    "# df[df.tic == '000921'].close.pct_change().hist(bins=100)\n",
    "# sns.distplot(df[df.tic == '000921'].close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "driving-bumper",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.distplot(df[df.tic == '000921'].close.pct_change())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "utility-warehouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stat, p = shapiro(df[df.tic == '000921'].close.pct_change())\n",
    "# stat, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "magnetic-behavior",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n"
     ]
    }
   ],
   "source": [
    "fe = FeatureEngineer(use_technical_indicator=True,\n",
    "                     use_turbulence=False,\n",
    "                     user_defined_feature = False)\n",
    "\n",
    "df = fe.preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "surrounded-sierra",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add covariance matrix as states\n",
    "df=df.sort_values(['date','tic'], ignore_index=True)\n",
    "df.index = df.date.factorize()[0]\n",
    "\n",
    "cov_list = []\n",
    "return_list = []\n",
    "\n",
    "# look back is one year\n",
    "lookback=252\n",
    "for i in range(lookback, len(df.index.unique())):\n",
    "    data_lookback = df.loc[i-lookback:i, :]\n",
    "    price_lookback = data_lookback.pivot_table(index = 'date',columns = 'tic', values = 'close')\n",
    "    return_lookback = price_lookback.pct_change().dropna()\n",
    "    return_list.append(return_lookback)\n",
    "\n",
    "    covs = return_lookback.cov().values\n",
    "    cov_list.append(covs)\n",
    "\n",
    "\n",
    "df_cov = pd.DataFrame({'date': df.date.unique()[lookback:], 'cov_list': cov_list,'return_list': return_list})\n",
    "df = df.merge(df_cov, on='date')\n",
    "df = df.sort_values(['date', 'tic']).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "filled-slide",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['daily_variance'] = (df.high - df.low) / df.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dressed-pepper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_2cd77_row0_col0, #T_2cd77_row1_col1 {\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2cd77_row0_col1, #T_2cd77_row1_col0 {\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_2cd77_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >tic</th>\n",
       "      <th class=\"col_heading level0 col0\" >000573</th>\n",
       "      <th class=\"col_heading level0 col1\" >300384</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >tic</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_2cd77_level0_row0\" class=\"row_heading level0 row0\" >000573</th>\n",
       "      <td id=\"T_2cd77_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "      <td id=\"T_2cd77_row0_col1\" class=\"data row0 col1\" >-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2cd77_level0_row1\" class=\"row_heading level0 row1\" >300384</th>\n",
       "      <td id=\"T_2cd77_row1_col0\" class=\"data row1 col0\" >-1.000000</td>\n",
       "      <td id=\"T_2cd77_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1e0d630dec8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = df.loc[-5:, :]\n",
    "dd = dl.pivot_table(index = 'date',columns = 'tic', values = 'close').pct_change().dropna()\n",
    "dd.cov().corr().style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "broad-advertising",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data_split(df, train_start, train_end) # 2021-07-01 2022-01-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "diagnostic-gambling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>volume</th>\n",
       "      <th>amount</th>\n",
       "      <th>tic</th>\n",
       "      <th>date</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>cov_list</th>\n",
       "      <th>return_list</th>\n",
       "      <th>daily_variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.95</td>\n",
       "      <td>2.98</td>\n",
       "      <td>2.99</td>\n",
       "      <td>2.91</td>\n",
       "      <td>2073802.0</td>\n",
       "      <td>6599088.5</td>\n",
       "      <td>000573</td>\n",
       "      <td>2019-01-15</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.011279</td>\n",
       "      <td>3.084834</td>\n",
       "      <td>2.730166</td>\n",
       "      <td>50.446237</td>\n",
       "      <td>13.350224</td>\n",
       "      <td>16.532907</td>\n",
       "      <td>2.946000</td>\n",
       "      <td>2.970167</td>\n",
       "      <td>[[0.0005653799165217271, 0.0002759971696522658...</td>\n",
       "      <td>tic           000573    300384\n",
       "date           ...</td>\n",
       "      <td>0.026846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.53</td>\n",
       "      <td>12.84</td>\n",
       "      <td>12.97</td>\n",
       "      <td>12.49</td>\n",
       "      <td>5185429.0</td>\n",
       "      <td>67292200.0</td>\n",
       "      <td>300384</td>\n",
       "      <td>2019-01-15</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.191671</td>\n",
       "      <td>12.893762</td>\n",
       "      <td>11.500238</td>\n",
       "      <td>46.908556</td>\n",
       "      <td>34.702436</td>\n",
       "      <td>3.310259</td>\n",
       "      <td>12.512333</td>\n",
       "      <td>13.449833</td>\n",
       "      <td>[[0.0005653799165217271, 0.0002759971696522658...</td>\n",
       "      <td>tic           000573    300384\n",
       "date           ...</td>\n",
       "      <td>0.037383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.99</td>\n",
       "      <td>2.97</td>\n",
       "      <td>2.99</td>\n",
       "      <td>2.95</td>\n",
       "      <td>1793157.0</td>\n",
       "      <td>5738352.5</td>\n",
       "      <td>000573</td>\n",
       "      <td>2019-01-16</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.006748</td>\n",
       "      <td>3.053570</td>\n",
       "      <td>2.747430</td>\n",
       "      <td>50.061021</td>\n",
       "      <td>24.744540</td>\n",
       "      <td>16.532907</td>\n",
       "      <td>2.943667</td>\n",
       "      <td>2.973500</td>\n",
       "      <td>[[0.0005651367811746447, 0.0002753845041580402...</td>\n",
       "      <td>tic           000573    300384\n",
       "date           ...</td>\n",
       "      <td>0.013468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.88</td>\n",
       "      <td>12.82</td>\n",
       "      <td>12.93</td>\n",
       "      <td>12.66</td>\n",
       "      <td>3037476.0</td>\n",
       "      <td>39304800.0</td>\n",
       "      <td>300384</td>\n",
       "      <td>2019-01-16</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.138345</td>\n",
       "      <td>12.911668</td>\n",
       "      <td>11.490332</td>\n",
       "      <td>46.797304</td>\n",
       "      <td>47.538639</td>\n",
       "      <td>3.310259</td>\n",
       "      <td>12.485000</td>\n",
       "      <td>13.412333</td>\n",
       "      <td>[[0.0005651367811746447, 0.0002753845041580402...</td>\n",
       "      <td>tic           000573    300384\n",
       "date           ...</td>\n",
       "      <td>0.021061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.97</td>\n",
       "      <td>2.93</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.93</td>\n",
       "      <td>1846921.0</td>\n",
       "      <td>5901182.5</td>\n",
       "      <td>000573</td>\n",
       "      <td>2019-01-17</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.006311</td>\n",
       "      <td>3.028462</td>\n",
       "      <td>2.759538</td>\n",
       "      <td>48.527648</td>\n",
       "      <td>14.138004</td>\n",
       "      <td>12.348249</td>\n",
       "      <td>2.938000</td>\n",
       "      <td>2.976333</td>\n",
       "      <td>[[0.0005657117990964307, 0.0002756551098127782...</td>\n",
       "      <td>tic           000573    300384\n",
       "date           ...</td>\n",
       "      <td>0.023891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    open  close   high    low     volume      amount     tic       date  day  \\\n",
       "0   2.95   2.98   2.99   2.91  2073802.0   6599088.5  000573 2019-01-15    1   \n",
       "0  12.53  12.84  12.97  12.49  5185429.0  67292200.0  300384 2019-01-15    1   \n",
       "1   2.99   2.97   2.99   2.95  1793157.0   5738352.5  000573 2019-01-16    2   \n",
       "1  12.88  12.82  12.93  12.66  3037476.0  39304800.0  300384 2019-01-16    2   \n",
       "2   2.97   2.93   3.00   2.93  1846921.0   5901182.5  000573 2019-01-17    3   \n",
       "\n",
       "       macd    boll_ub    boll_lb     rsi_30     cci_30      dx_30  \\\n",
       "0 -0.011279   3.084834   2.730166  50.446237  13.350224  16.532907   \n",
       "0 -0.191671  12.893762  11.500238  46.908556  34.702436   3.310259   \n",
       "1 -0.006748   3.053570   2.747430  50.061021  24.744540  16.532907   \n",
       "1 -0.138345  12.911668  11.490332  46.797304  47.538639   3.310259   \n",
       "2 -0.006311   3.028462   2.759538  48.527648  14.138004  12.348249   \n",
       "\n",
       "   close_30_sma  close_60_sma  \\\n",
       "0      2.946000      2.970167   \n",
       "0     12.512333     13.449833   \n",
       "1      2.943667      2.973500   \n",
       "1     12.485000     13.412333   \n",
       "2      2.938000      2.976333   \n",
       "\n",
       "                                            cov_list  \\\n",
       "0  [[0.0005653799165217271, 0.0002759971696522658...   \n",
       "0  [[0.0005653799165217271, 0.0002759971696522658...   \n",
       "1  [[0.0005651367811746447, 0.0002753845041580402...   \n",
       "1  [[0.0005651367811746447, 0.0002753845041580402...   \n",
       "2  [[0.0005657117990964307, 0.0002756551098127782...   \n",
       "\n",
       "                                         return_list  daily_variance  \n",
       "0  tic           000573    300384\n",
       "date           ...        0.026846  \n",
       "0  tic           000573    300384\n",
       "date           ...        0.037383  \n",
       "1  tic           000573    300384\n",
       "date           ...        0.013468  \n",
       "1  tic           000573    300384\n",
       "date           ...        0.021061  \n",
       "2  tic           000573    300384\n",
       "date           ...        0.023891  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "express-gravity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>volume</th>\n",
       "      <th>amount</th>\n",
       "      <th>tic</th>\n",
       "      <th>date</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>cov_list</th>\n",
       "      <th>return_list</th>\n",
       "      <th>daily_variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [open, close, high, low, volume, amount, tic, date, day, macd, boll_ub, boll_lb, rsi_30, cci_30, dx_30, close_30_sma, close_60_sma, cov_list, return_list, daily_variance]\n",
       "Index: []"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['cci_30'] == np.inf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "precious-jefferson",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gym.utils import seeding\n",
    "import gym\n",
    "from gym import spaces\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "\n",
    "class StockPortfolioEnv(gym.Env):\n",
    "    \"\"\"A portfolio allocation environment for OpenAI gym\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "        df: DataFrame\n",
    "            input data\n",
    "        stock_dim : int\n",
    "            number of unique stocks\n",
    "        hmax : int\n",
    "            maximum number of shares to trade\n",
    "        initial_amount : int\n",
    "            start money\n",
    "        transaction_cost_pct: float\n",
    "            transaction cost percentage per trade\n",
    "        reward_scaling: float\n",
    "            scaling factor for reward, good for training\n",
    "        state_space: int\n",
    "            the dimension of input features\n",
    "        action_space: int\n",
    "            equals stock dimension\n",
    "        tech_indicator_list: list\n",
    "            a list of technical indicator names\n",
    "        turbulence_threshold: int\n",
    "            a threshold to control risk aversion\n",
    "        day: int\n",
    "            an increment number to control date\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    _sell_stock()\n",
    "        perform sell action based on the sign of the action\n",
    "    _buy_stock()\n",
    "        perform buy action based on the sign of the action\n",
    "    step()\n",
    "        at each step the agent will return actions, then \n",
    "        we will calculate the reward, and return the next observation.\n",
    "    reset()\n",
    "        reset the environment\n",
    "    render()\n",
    "        use render to return other functions\n",
    "    save_asset_memory()\n",
    "        return account value at each time step\n",
    "    save_action_memory()\n",
    "        return actions/positions at each time step\n",
    "        \n",
    "\n",
    "    \"\"\"\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self,\n",
    "                 df,\n",
    "                 stock_dim,\n",
    "                 hmax,\n",
    "                 initial_amount,\n",
    "                 transaction_cost_pct,\n",
    "                 reward_scaling,\n",
    "                 state_space,\n",
    "                 action_space,\n",
    "                 tech_indicator_list,\n",
    "                 turbulence_threshold=None,\n",
    "                 lookback=252,\n",
    "                 day=0):\n",
    "        #super(StockEnv, self).__init__()\n",
    "        #money = 10 , scope = 1\n",
    "        self.day = day\n",
    "        self.lookback=lookback\n",
    "        self.df = df\n",
    "        self.stock_dim = stock_dim\n",
    "        self.hmax = hmax\n",
    "        self.initial_amount = initial_amount\n",
    "#         self.reward = initial_amount\n",
    "        self.transaction_cost_pct =transaction_cost_pct\n",
    "        self.reward_scaling = reward_scaling\n",
    "        self.state_space = state_space\n",
    "        self.action_space = action_space\n",
    "        self.tech_indicator_list = tech_indicator_list\n",
    "\n",
    "        # action_space normalization and shape is self.stock_dim\n",
    "        self.action_space = spaces.Box(low=0, high=1,shape=(self.action_space,))\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape = (self.state_space+len(self.tech_indicator_list),self.state_space))\n",
    "\n",
    "        # load data from a pandas dataframe\n",
    "        self.data = self.df.loc[self.day,:]\n",
    "        self.covs = self.data['cov_list'].values[0]\n",
    "        self.state =  np.append(np.array(self.covs), [self.data[tech].values.tolist() for tech in self.tech_indicator_list ], axis=0)\n",
    "        self.terminal = False\n",
    "        self.turbulence_threshold = turbulence_threshold\n",
    "        # initalize state: inital portfolio return + individual stock return + individual weights\n",
    "        self.portfolio_value = self.initial_amount\n",
    "\n",
    "        # memorize portfolio value each step\n",
    "        self.asset_memory = [self.initial_amount]\n",
    "        # memorize portfolio return each step\n",
    "        self.portfolio_return_memory = [0]\n",
    "        self.actions_memory=[[1 / self.stock_dim] * self.stock_dim]\n",
    "        self.date_memory=[self.data.date.unique()[0]]\n",
    "\n",
    "        \n",
    "    def step(self, actions):\n",
    "        self.terminal = self.day >= len(self.df.index.unique()) - 1\n",
    "\n",
    "        if self.terminal:\n",
    "            df = pd.DataFrame(self.portfolio_return_memory)\n",
    "            df.columns = ['daily_return']\n",
    "#             plt.plot(df.daily_return.cumsum(),'r')\n",
    "#             plt.savefig('results/cumulative_reward.png')\n",
    "#             plt.close()\n",
    "            \n",
    "#             plt.plot(self.portfolio_return_memory,'r')\n",
    "#             plt.savefig('results/rewards.png')\n",
    "#             plt.close()\n",
    "\n",
    "            print(\"=================================\")\n",
    "            print(\"begin_total_asset:{}\".format(self.asset_memory[0]))\n",
    "            print(\"end_total_asset:{}\".format(self.portfolio_value))\n",
    "\n",
    "            df_daily_return = pd.DataFrame(self.portfolio_return_memory)\n",
    "            df_daily_return.columns = ['daily_return']\n",
    "            if df_daily_return['daily_return'].std() != 0:\n",
    "                sharpe = (252 ** 0.5) * df_daily_return['daily_return'].mean() / df_daily_return['daily_return'].std()\n",
    "                print(\"Sharpe: \", sharpe)\n",
    "            print(\"=================================\")\n",
    "            \n",
    "            return self.state, self.reward, self.terminal,{}\n",
    "\n",
    "        else:\n",
    "            weights = self.softmax_normalization(actions)\n",
    "            self.actions_memory.append(weights)\n",
    "            last_day_memory = self.data\n",
    "\n",
    "            #load next state\n",
    "            self.day += 1\n",
    "            self.data = self.df.loc[self.day,:]\n",
    "            self.covs = self.data['cov_list'].values[0]\n",
    "            self.state = np.append(np.array(self.covs), [self.data[tech].values.tolist() for tech in self.tech_indicator_list], axis=0)\n",
    "            portfolio_return = sum(((self.data.close.values / last_day_memory.close.values) - 1) * weights)\n",
    "#             log_portfolio_return = np.log(sum((self.data.close.values / last_day_memory.close.values) * weights))\n",
    "            # update portfolio value\n",
    "            new_portfolio_value = self.portfolio_value * (1 + portfolio_return)\n",
    "#             new_portfolio_value = self.portfolio_value * (1 + log_portfolio_return)\n",
    "            self.portfolio_value = new_portfolio_value\n",
    "\n",
    "            # save into memory\n",
    "            self.portfolio_return_memory.append(portfolio_return)\n",
    "            self.date_memory.append(self.data.date.unique()[0])\n",
    "            self.asset_memory.append(new_portfolio_value)\n",
    "\n",
    "            # the reward is the new portfolio value or end portfolo value\n",
    "            self.reward = new_portfolio_value / self.initial_amount\n",
    "\n",
    "        return self.state, self.reward, self.terminal, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.asset_memory = [self.initial_amount]\n",
    "        self.day = 0\n",
    "        self.data = self.df.loc[self.day, :]\n",
    "        # load states\n",
    "        self.covs = self.data['cov_list'].values[0]\n",
    "        self.state =  np.append(np.array(self.covs), [self.data[tech].values.tolist() for tech in self.tech_indicator_list ], axis=0)\n",
    "        self.portfolio_value = self.initial_amount\n",
    "        #self.cost = 0\n",
    "        #self.trades = 0\n",
    "        self.terminal = False\n",
    "        self.portfolio_return_memory = [0]\n",
    "        self.actions_memory=[[1/self.stock_dim]*self.stock_dim]\n",
    "        self.date_memory=[self.data.date.unique()[0]]\n",
    "        return self.state\n",
    "    \n",
    "    def render(self, mode='human'):\n",
    "        return self.state\n",
    "        \n",
    "    def softmax_normalization(self, actions):\n",
    "        numerator = np.exp(actions)\n",
    "        denominator = np.sum(np.exp(actions))\n",
    "        softmax_output = numerator / denominator\n",
    "        return softmax_output\n",
    "\n",
    "    \n",
    "    def save_asset_memory(self):\n",
    "        date_list = self.date_memory\n",
    "        portfolio_return = self.portfolio_return_memory\n",
    "        #print(len(date_list))\n",
    "        #print(len(asset_list))\n",
    "        df_account_value = pd.DataFrame({'date':date_list,'daily_return':portfolio_return})\n",
    "        return df_account_value\n",
    "\n",
    "    def save_action_memory(self):\n",
    "        # date and close price length must match actions length\n",
    "        date_list = self.date_memory\n",
    "        df_date = pd.DataFrame(date_list)\n",
    "        df_date.columns = ['date']\n",
    "        \n",
    "        action_list = self.actions_memory\n",
    "        df_actions = pd.DataFrame(action_list)\n",
    "        df_actions.columns = self.data.tic.values\n",
    "        df_actions.index = df_date.date\n",
    "        #df_actions = pd.DataFrame({'date':date_list,'actions':action_list})\n",
    "        return df_actions\n",
    "\n",
    "    def _seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "\n",
    "    def get_sb_env(self):\n",
    "        e = DummyVecEnv([lambda: self])\n",
    "        obs = e.reset()\n",
    "        return e, obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "korean-respect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 2, State Space: 2\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = stock_dimension\n",
    "print(f'Stock Dimension: {stock_dimension}, State Space: {state_space}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "magnetic-identifier",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['daily_variance', 'change', 'log_volume', 'close','day', 'macd', 'rsi_30', 'boll_ub', 'dx_30']\n",
    "# ['macd', 'boll_ub', 'boll_lb', 'rsi_30', 'boll_ub', 'dx_30', 'close_30_sma', 'close_60_sma'] # cci_30\n",
    "tech_indicator_list = ['macd', 'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 'daily_variance', 'dx_30', 'close_30_sma', 'close_60_sma']\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100, \n",
    "    \"initial_amount\": 20000, \n",
    "    \"transaction_cost_pct\": 0, \n",
    "    \"state_space\": state_space, \n",
    "    \"stock_dim\": stock_dimension, \n",
    "    \"tech_indicator_list\": tech_indicator_list, # config.TECHNICAL_INDICATORS_LIST, \n",
    "    \"action_space\": stock_dimension, \n",
    "    \"reward_scaling\": 1e-1\n",
    "    \n",
    "}\n",
    "\n",
    "e_train_gym = StockPortfolioEnv(df = train, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "generic-sussex",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    }
   ],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "double-nylon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 2048, 'ent_coef': 0.005, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.005,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "model_ppo = agent.get_model(\"ppo\", model_kwargs = PPO_PARAMS, tensorboard_log='D:/code/python/logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "heard-anniversary",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\soft\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "d:\\soft\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "d:\\soft\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "d:\\soft\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "d:\\soft\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "d:\\soft\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to D:/code/python/logs\\ppo_4\n",
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:39557.557966440254\n",
      "Sharpe:  0.7920445604730186\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:31016.91388795167\n",
      "Sharpe:  0.5805189984034913\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    fps             | 338       |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 6         |\n",
      "|    total_timesteps | 2048      |\n",
      "| train/             |           |\n",
      "|    reward          | 1.1199421 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:32857.90241315552\n",
      "Sharpe:  0.6318856563536209\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:30395.183546113665\n",
      "Sharpe:  0.5616642224322729\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:35138.221443642244\n",
      "Sharpe:  0.6953582458661234\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 403          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049966136 |\n",
      "|    clip_fraction        | 0.0195       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0.0367       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 151          |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0048      |\n",
      "|    reward               | 1.3466314    |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 351          |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:39494.50367721083\n",
      "Sharpe:  0.8059190114384069\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:33688.617598442426\n",
      "Sharpe:  0.658271846102519\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:37709.8087242037\n",
      "Sharpe:  0.7515057140221001\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 430          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044581336 |\n",
      "|    clip_fraction        | 0.0132       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0.027        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 130          |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00463     |\n",
      "|    reward               | 1.182641     |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 315          |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:27185.477706886963\n",
      "Sharpe:  0.46378656946734176\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:34310.01787270822\n",
      "Sharpe:  0.6728451166770792\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 445          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 18           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031186834 |\n",
      "|    clip_fraction        | 0.00571      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0.0367       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 164          |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00303     |\n",
      "|    reward               | 1.5927519    |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 365          |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:32325.40083282057\n",
      "Sharpe:  0.6198544208113022\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:32786.259471754514\n",
      "Sharpe:  0.6367741142761804\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:32696.841900657655\n",
      "Sharpe:  0.6281246239863107\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 455          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 22           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024243721 |\n",
      "|    clip_fraction        | 0.00298      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0.0462       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 125          |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00316     |\n",
      "|    reward               | 1.0152451    |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 289          |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:30240.824629895036\n",
      "Sharpe:  0.5545956921838916\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:32389.472960965893\n",
      "Sharpe:  0.6199543997833796\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:34226.55611565727\n",
      "Sharpe:  0.6703520677068301\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 461          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 26           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017667894 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0.0409       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 139          |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.00234     |\n",
      "|    reward               | 1.3024983    |\n",
      "|    std                  | 0.996        |\n",
      "|    value_loss           | 300          |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:35478.35420067066\n",
      "Sharpe:  0.7015395115028746\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:38531.88824502572\n",
      "Sharpe:  0.7748758383744432\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:35637.31176543448\n",
      "Sharpe:  0.7097817126334675\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 465          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 30           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040555405 |\n",
      "|    clip_fraction        | 0.0131       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0.0363       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 128          |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00434     |\n",
      "|    reward               | 1.2446187    |\n",
      "|    std                  | 0.993        |\n",
      "|    value_loss           | 288          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:38425.38777052381\n",
      "Sharpe:  0.7739317890123567\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:35107.4406357461\n",
      "Sharpe:  0.6937701084842474\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 469          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 34           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033071456 |\n",
      "|    clip_fraction        | 0.00742      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0.0269       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 145          |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.0038      |\n",
      "|    reward               | 1.613126     |\n",
      "|    std                  | 0.996        |\n",
      "|    value_loss           | 322          |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:32256.29499521572\n",
      "Sharpe:  0.6221116933902336\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:32967.521562226066\n",
      "Sharpe:  0.6393317002641321\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:38441.41244451351\n",
      "Sharpe:  0.7759160472090699\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 472          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 38           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017498634 |\n",
      "|    clip_fraction        | 0.00122      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0.0207       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 138          |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00285     |\n",
      "|    reward               | 1.1035635    |\n",
      "|    std                  | 0.998        |\n",
      "|    value_loss           | 296          |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:29964.53450312301\n",
      "Sharpe:  0.5487805821262686\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:44149.69314496263\n",
      "Sharpe:  0.8965773157327144\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:39539.90806455494\n",
      "Sharpe:  0.7973548413528109\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 474         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002045008 |\n",
      "|    clip_fraction        | 0.00283     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.83       |\n",
      "|    explained_variance   | 0.0177      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 138         |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00309    |\n",
      "|    reward               | 1.1230086   |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 295         |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:27624.21906444726\n",
      "Sharpe:  0.48071501729856786\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:38081.76734731368\n",
      "Sharpe:  0.7634209190593876\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:33969.26002747427\n",
      "Sharpe:  0.6626782488280221\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 476          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 47           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031215404 |\n",
      "|    clip_fraction        | 0.00508      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0.00862      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 148          |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.0037      |\n",
      "|    reward               | 1.2288145    |\n",
      "|    std                  | 0.997        |\n",
      "|    value_loss           | 310          |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:32022.90306175816\n",
      "Sharpe:  0.6054851291340971\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:35184.74403910581\n",
      "Sharpe:  0.6946220764524393\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 477         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002183298 |\n",
      "|    clip_fraction        | 0.00352     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.83       |\n",
      "|    explained_variance   | 0.0126      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 129         |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00335    |\n",
      "|    reward               | 1.2934963   |\n",
      "|    std                  | 0.997       |\n",
      "|    value_loss           | 285         |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:27953.229346508626\n",
      "Sharpe:  0.48857307912773434\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:29536.938416343703\n",
      "Sharpe:  0.5369693958915197\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:38555.82861332421\n",
      "Sharpe:  0.7681334644095966\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 479          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 55           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037056599 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0.0134       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 113          |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00373     |\n",
      "|    reward               | 1.3602515    |\n",
      "|    std                  | 0.997        |\n",
      "|    value_loss           | 238          |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:41751.89321492709\n",
      "Sharpe:  0.8318401512785224\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:41058.800689370364\n",
      "Sharpe:  0.8261442058012607\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:36190.61661601108\n",
      "Sharpe:  0.7123704938736313\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 480          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 59           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026009858 |\n",
      "|    clip_fraction        | 0.00796      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0.0101       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 149          |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00522     |\n",
      "|    reward               | 1.3060628    |\n",
      "|    std                  | 0.998        |\n",
      "|    value_loss           | 305          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:34629.443720718504\n",
      "Sharpe:  0.6856875251980455\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:35664.53411883957\n",
      "Sharpe:  0.7035187129705422\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:36480.509670692096\n",
      "Sharpe:  0.7291231848832385\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 481          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 63           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024193544 |\n",
      "|    clip_fraction        | 0.011        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0.00982      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 143          |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00586     |\n",
      "|    reward               | 1.2566676    |\n",
      "|    std                  | 0.997        |\n",
      "|    value_loss           | 296          |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:44365.463154997844\n",
      "Sharpe:  0.8924361387857559\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:32903.41809054995\n",
      "Sharpe:  0.6346808753305742\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 481          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 67           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036535736 |\n",
      "|    clip_fraction        | 0.0113       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0.0111       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 127          |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.00494     |\n",
      "|    reward               | 1.4806621    |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 263          |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:31731.64835252951\n",
      "Sharpe:  0.6065250183371325\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:33623.452470976554\n",
      "Sharpe:  0.6514306258317422\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:31772.68762361137\n",
      "Sharpe:  0.6049074144272825\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 482          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 72           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039456272 |\n",
      "|    clip_fraction        | 0.0141       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0.00745      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 135          |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00371     |\n",
      "|    reward               | 1.0813733    |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 286          |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:32108.797389488376\n",
      "Sharpe:  0.6102390601174391\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:34582.49634109026\n",
      "Sharpe:  0.6855016335735112\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:34701.81813978179\n",
      "Sharpe:  0.6806399829330797\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 483          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 76           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038657207 |\n",
      "|    clip_fraction        | 0.0165       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0.0112       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 115          |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00516     |\n",
      "|    reward               | 1.2066667    |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 245          |\n",
      "------------------------------------------\n",
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:32160.961179234877\n",
      "Sharpe:  0.6108770355270277\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:43896.49863613887\n",
      "Sharpe:  0.8892272842526224\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:41077.24389344975\n",
      "Sharpe:  0.8316367988857376\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 483         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 80          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003632289 |\n",
      "|    clip_fraction        | 0.013       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.84       |\n",
      "|    explained_variance   | 0.0103      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 112         |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00452    |\n",
      "|    reward               | 1.0964128   |\n",
      "|    std                  | 0.999       |\n",
      "|    value_loss           | 234         |\n",
      "-----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:33256.35636951501\n",
      "Sharpe:  0.6427846234433622\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:32028.406158180343\n",
      "Sharpe:  0.6119030258259347\n",
      "=================================\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 484          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 84           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039329776 |\n",
      "|    clip_fraction        | 0.0185       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.83        |\n",
      "|    explained_variance   | 0.00681      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 150          |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.00652     |\n",
      "|    reward               | 1.5909617    |\n",
      "|    std                  | 0.997        |\n",
      "|    value_loss           | 307          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x1e0d62bdf88>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.train_model(model=model_ppo, tb_log_name='ppo', total_timesteps=40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "every-schedule",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade = data_split(df, trade_start, trade_end) # '2021-12-20', '2023-01-01' trade_start, trade_end\n",
    "e_trade_gym = StockPortfolioEnv(df = trade, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "particular-tongue",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tic = trade.tic.unique()\n",
    "unique_trade_date = trade.date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "flying-opposition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:20000\n",
      "end_total_asset:20231.97554182795\n",
      "Sharpe:  2.368550439442704\n",
      "=================================\n",
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "df_daily_return_ppo, df_actions_ppo = DRLAgent.DRL_prediction(model=model_ppo, environment=e_trade_gym)\n",
    "time_ind = pd.Series(df_daily_return_ppo.date)\n",
    "ppo_cumpod =(df_daily_return_ppo.daily_return + 1).cumprod() - 1\n",
    "DRL_strat_ppo = convert_daily_return_to_pyfolio_ts(df_daily_return_ppo)\n",
    "\n",
    "perf_func = timeseries.perf_stats \n",
    "\n",
    "perf_stats_all_ppo = perf_func(returns=DRL_strat_ppo, \n",
    "                               factor_returns=DRL_strat_ppo, \n",
    "                               positions=None, transactions=None, turnover_denom='AGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominant-verification",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerous-canon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-giving",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "concrete-spanish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import squarify \n",
    "# %matplotlib inline\n",
    "# sizes=[40, 30, 5, 25]\n",
    "# label=[\"A\", \"B\", \"C\", \"D\"]\n",
    "# squarify.plot(sizes=sizes, label=label, alpha=0.6)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standing-turkish",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
